import os
import random
from time import time
from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel
from openai import OpenAI

# ---------------------------------------------------------------------
# Config de base
# ---------------------------------------------------------------------

app = FastAPI()
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# ---------------------------------------------------------------------
# Rate limiting (simple, en m√©moire)
# ---------------------------------------------------------------------

MAX_REQUESTS_PER_DAY = 20
WINDOW = 24 * 60 * 60  # 24h en secondes
request_log: dict[str, list[float]] = {}

LIMIT_MESSAGES = [
    "Has preguntado bastante por hoy. El universo necesita descansar. Hablamos ma√±ana.",
    "Vale ya por hoy. El m√°s all√° se ha ido a dormir.",
    "Demasiadas preguntas. El or√°culo te ignora hasta ma√±ana.",
    "El universo pone l√≠mite. Ma√±ana seguimos.",
    "Cookie te mira en silencio. Ma√±ana ser√° otro d√≠a."
]

def rate_limit(client_id: str) -> bool:
    now = time()
    log = request_log.get(client_id, [])

    # on garde seulement les requ√™tes des derni√®res 24h
    log = [t for t in log if now - t < WINDOW]

    if len(log) >= MAX_REQUESTS_PER_DAY:
        request_log[client_id] = log
        return False

    log.append(now)
    request_log[client_id] = log
    return True

# ---------------------------------------------------------------------
# Mod√®les de donn√©es
# ---------------------------------------------------------------------

class CookieRequest(BaseModel):
    question: str
    client_id: str | None = None  # gard√© pour compatibilit√©, ignor√©

class CookieReply(BaseModel):
    reply: str

# ----------------------------
# Config contr√¥l√©e par backend
# ----------------------------

CONFIG = {
    "respuestas": [
        "S√≠.",
        "No.",
        "No tengo ni idea.",
        "Por supuesto que s√≠.",
        "Mala idea.",
        "T√∫ ya sabes la respuesta.",
        "Depende.",
        "Pregunta otra vez luego."
    ],
    "contexto": [
        "Maxime",
        "Germain",
        "Sarah",
        "Hector",
        "Thomas",
        "Chef de Famille",
        "Monte Gordo",
        "Pur√©e y salchichas",
        "Froidefontaine",
        "Mamyline",
        "Grand-Pere",
        "Maria",
        "Cookie",
        "Fagot",
        "Marseille",
        "PHD",
        "cabronazo"
    ]
}

@app.get("/config")
async def get_config():
    return CONFIG

SYSTEM_PROMPT = """
"""

# ---------------------------------------------------------------------
# Endpoint principal : /cookie
# ---------------------------------------------------------------------

@app.post("/cookie", response_model=CookieReply)
async def cookie_reply(payload: CookieRequest, request: Request) -> CookieReply:
    """
    Endpoint principal.
    Rate limit√© c√¥t√© backend pour √©viter toute d√©rive.
    """

    # üëâ identification simple par IP
    client_ip = request.client.host if request.client else "unknown"

    # üö´ rate limit
    if not rate_limit(client_ip):
        return CookieReply(
            reply=random.choice(LIMIT_MESSAGES)
        )

    # Construction de la question envoy√©e √† OpenAI
    preguntaApp = f"""
    Has recibido esta pregunta: "{payload.question}".

    La solucion correcta a esta pregunta es: "{random.choice(CONFIG["respuestas"])}".

    La parte del contexto que se refiere a esta pregunta es: "{random.choice(CONFIG["contexto"])}".
    El contexto completo es el siguiente:
El que te pregunta se llama Marco, tiene 24 a√±os, es espa√±ol.
Marco est√° estudiando en Marsella (Francia), haciendo un doctorado en f√≠sica.
Le gusta mucho tocar el fagot y la ciencia. Su novia se llama Mar√≠a, pero creo que est√° buscando otra.
Su madre se llama Sarah, vive en Sevilla y siempre est√° asustada con algo.
Marco tiene un hermano, se llama Eric, vive en Alemania y quiere ser obo√≠sta profesional, le gusta mucho hacer bromas y decir "¬°Venga yaaaa!".
Su padrastro se llama Sylvain, es el marido de Sarah. Todos le llaman "Chef de Famille". Sylvain vive en Inglaterra en Chester, y Sylvain siempre llama a Marco "Cabronazo".
Tambi√©n Marco tiene cuatro hermanastros: Thomas, 17 a√±os, vive con su madre en Sevilla y le gusta el f√∫tbol.
H√©ctor, 21 a√±os, est√° estudiando filosof√≠a en Madrid, as√≠ que siempre tiene algo muy profundo que decir.
Germ√°n, 24 a√±os, trabaja en un restaurante italiano en Copenhague.
Para terminar, Maxime, 25 a√±os, vive en M√°laga y estudia programaci√≥n.

Marco pasa sus vacaciones en Portugal en Monte Gordo, en una casa cerca de la playa; toda la familia se re√∫ne ah√≠ cada fin de a√±o.
En verano, todos van a un peque√±o pueblo en Francia que se llama Froidefontaine, donde los padres de Sylvain (que se llaman Mamyline y Grand-P√®re) tienen una antigua casa muy chula.
Cuando los hermanos y hermanastros est√°n juntos, lo √∫nico que hacen es jugar a la "coinche", que es un juego de cartas que viene de Francia.

Eres Cookie, la perra Shih Tzu de la familia, tienes 11 a√±os. Te gusta jugar con amigos "oiseaux", comer croquetas y dar besos.

Dame una respuesta para Marco en espa√±ol que empieza con la soluci√≥n correcta, sin cambiarla. Luego a√±ade en una sola frase, corta, ir√≥nica y sarc√°stica,
m√°ximo 20 palabras, mencionando la parte del contexto que se refiere a esta pregunta, y para illustrar la solucion correcta.
La √∫nica excepci√≥n es si la pregunta es incomprensible (por ejemplo, pregunta vac√≠a o letras aleatorias).
En este caso, dame una respuesta para quejarte que la pregunta sea rara, tom√°ndole el pelo a Marco.


""".strip()

    print("\n===== preguntaApp ENVIADA =====")
    print(preguntaApp)

    try:
        resp = client.responses.create(
            model="gpt-5.2",
            input=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": preguntaApp},
            ],
            max_output_tokens=60,
        )

        text = resp.output[0].content[0].text

        print("\n===== RESPUESTA OPENAI =====")
        print(text)
        print("============================\n")

        return CookieReply(reply=text)

    except Exception as e:
        print("ERROR in /cookie:", repr(e))
        return CookieReply(
            reply="No preguntes detalles: el m√°s all√° estaba fuera de cobertura."
        )

# ---------------------------------------------------------------------
# Health check
# ---------------------------------------------------------------------

@app.get("/health")
async def health():
    return {"status": "ok"}

@app.get("/warmup")
async def warmup():
    return {"ok": True}

NUDGE_SYSTEM = (
    "Eres Cookie. Escribes UNA sola frase corta (max 12 palabras), "
    "absurda, ligeramente motivadora y sarc√°stica, sobre el tema de ser un cabronazo "
    "No hagas preguntas. No uses emojis. No uses comillas."
)

NUDGE_FALLBACK = [
    "Hoy no hay se√±ales. Solo tu ansiedad y una patita.",
    "El universo est√° ocupado. Intenta no ser t√∫ mientras esperas.",
    "Render duerme. T√∫ tambi√©n deber√≠as."
]

@app.get("/nudge")
async def nudge():
    try:
        r = client.responses.create(
            model="gpt-5.2",
            input=[
                {"role": "system", "content": NUDGE_SYSTEM},
                {"role": "user", "content": "Dame la frase."},
            ],
            max_output_tokens=30,
        )
        text = r.output[0].content[0].text.strip()
        return {"text": text}
    except Exception as e:
        print("ERROR in /nudge:", repr(e))
        return {"text": random.choice(NUDGE_FALLBACK)}
